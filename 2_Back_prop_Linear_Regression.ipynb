{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week3\n",
    "\n",
    "[참고 Link]\n",
    "- <a href=\"https://datascienceschool.net/view-notebook/4642b9f187784444b8f3a8309c583007\"> 데이터 사이언스 스쿨 - 최적화 기초</a>\n",
    "\n",
    "- <a href=\"http://shuuki4.github.io/deep%20learning/2016/05/20/Gradient-Descent-Algorithm-Overview.html\"> BEOMSU KIM'S BLOG - Gradient Descent Optimization Algorithms 정리</a>\n",
    "\n",
    "- <a href=\"http://solarisailab.com/archives/2237\"> 솔라리스의 인공지능 연구실 - Neural Networks의 학습속도 저하(Slowdown)를 막는 Cross-Entropy Cost Function</a>\n",
    "\n",
    "- <a href=\"http://sanghyukchun.github.io/58/\"> SanghyukChun's Blog - Machine Learning 스터디 (2) Probability Theory</a>\n",
    "\n",
    "- <a href=\"http://jaejunyoo.blogspot.com/2018/02/minimizing-negative-log-likelihood-in-kor-3.html\"> Jaejun Yoo's Playground - Minimizing the Negative Log-Likelihood, in Korean (3)</a>\n",
    "\n",
    "- <a href=\"https://taeoh-kim.github.io/blog/cross-entropy%EC%9D%98-%EC%A0%95%ED%99%95%ED%95%9C-%ED%99%95%EB%A5%A0%EC%A0%81-%EC%9D%98%EB%AF%B8/\"> Taeoh Kim's Blog - Cross Entropy의 정확한 확률적 의미</a>\n",
    "\n",
    "- <a href=\"http://funmv2013.blogspot.com/2017/01/cross-entropy.html\"> funMV - 분류 오차에 Cross entropy를 사용하는 이유</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "- random variable의 parameter를 estimate하는 방법 중 하나\n",
    "- 오직 주어진 Observation, 혹은 데이터들 만을 토대로 parameter estimation을 하는 방법이다. \n",
    "- 우리는 현재 우리가 갖고 있는 데이터가 가장 나옴직한 parameter를 고르고 싶을 것이고, 바로 이게 maximum likelihood estimate 입니다.<br><br>\n",
    "### $$ \\underset{\\theta}{\\arg\\max}\\ P(y\\,\\vert\\, x; \\theta) $$\n",
    "\n",
    "다만 확률 값은 [0,1] 안에서 결정되기 때문에 확률 값들을 여러 차례 곱하면 값이 매우 빠르게 작아집니다.<br>\n",
    "이런 현상을 방지하기 위해 log-likelihood를 사용하게 되는 것입니다. 또한 log의 성질 덕에 곱하기 연산이 더하기로 바뀌게 됩니다.\n",
    "\n",
    "보통 negative log likelihood(NLL) function 을 **목적함수**로 놓고 최소화 시키면서 최적의 parameter 를 찾는 것이 딥러닝 학습의 시작단계!\n",
    "\n",
    "### $$ \\underset{\\theta}{\\arg\\min}\\ -logP(y\\,\\vert\\, x; \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적화 문제는 함수 $f$의 값을 최대화 혹은 최소화하는 변수 $x$의 값 $x^{\\ast}$를 찾는 것이다. 수식으로는 다음처럼 쓴다.\n",
    "\n",
    "$$ x^{\\ast} = \\arg \\max_x f(x) \\;\\;(\\text{최대화의 경우}) $$\n",
    "\n",
    "$$ x^{\\ast} = \\arg \\min_x f(x) \\;\\;(\\text{최소화의 경우}) $$\n",
    "\n",
    "이 값 $x^{\\ast}$를 최적화 문제의 해(solution)라고 한다.\n",
    "\n",
    "최대화 문제는 $f(x)$ 를 $-f(x)$ 로 바꾸면 풀 수 있으므로 보통 최소화의 경우만 고려한다.\n",
    "\n",
    "이 때 최소화하고자 하는 함수 $f(x)$를 **목적함수(objective function)**, **비용함수(cost function)** 또는 **손실함수(loss function)** 등으로 부른다. 기호로는 각각 $J, C, L$로 표기하는 경우가 많다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight(parameter) Update\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1y7KfiZ82K7A5U0Ug2T7eyqVblkKWFTsF\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "### 1. Mean Squared Error - Regression\n",
    "\n",
    "<img src=\"http://solarisailab.com/wp-content/ql-cache/quicklatex.com-9b581a798d41c0cfec39bac20ee6fb50_l3.png\">\n",
    "\n",
    "이를 Neural Networks의 모델에 적용해서 표현하면 Neural Networks에서 output unit에서의 Cost function-J(W,b;x,y)-은 모델의 예측값(Prediction)-$\\sigma(z)$-과 실제 타겟값(True target value)-$y$-과의 차이를 제곱한 값으로 정의된다. (참고 : $z=Wx+b$, 계산의 편의성을 위해서 $\\frac{1}{2}$을 식에 추가함)\n",
    "\n",
    "<img src=\"http://solarisailab.com/wp-content/ql-cache/quicklatex.com-a39c609db4ee22c8d2c903662bb7eb0b_l3.png\">\n",
    "\n",
    "Neural Networks를 학습시키기 위해서는 Cost function-J(W,b;x,y)-의 미분값(derivative)를 계산해서 Neural Networks의 파라미터 W, b를 업데이트해야한다.MSE Cost function을 이용했을 경우 Weight와 Bias의 미분값(Derivative)를 계산하면 아래와 같다.\n",
    "(참고 : $\\sigma$ 는 activation function )\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1FhQqiE5zevi_1CWvTSK4VKdj8tzUkztN\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Average Cross Entropy Loss - Classification\n",
    "\n",
    "<img src=\"http://solarisailab.com/wp-content/ql-cache/quicklatex.com-49fd6c934151da1c89e8caf78cff9a82_l3.png\">\n",
    "\n",
    "Cross-Entropy Cost Function을 이용했을 때 Neural Networks의 파라미터인 Weight의 미분값(Derivative)를 계산하면 아래와 같다.<br><br>\n",
    "\n",
    "<img src=\"http://solarisailab.com/wp-content/ql-cache/quicklatex.com-c7343077fef6b09b1dbdc5238dcfa349_l3.png\"><br>\n",
    "<img src=\"https://drive.google.com/uc?id=14-jR7eoynt5RajadL-l8MThfVGZRJEZH\"><br>\n",
    "sigmoid function은 $\\sigma(z)=\\frac{1}{(1+e^{-z})}$로 정의되고 이를 미분하면 $\\sigma'(z)=\\sigma(z)(1-\\sigma(z))$이다. <br>\n",
    "따라서 이를 이용해 위 식을 다시한번 정리하면 최종적으로 Cross-Entropy를 이용한 Cost Function-J(W,b;x,y)-의 Weight와 bias의 미분값(Derivative)은 <br>\n",
    "아래와 같이 계산된다.\n",
    "\n",
    "<img src=\"http://solarisailab.com/wp-content/ql-cache/quicklatex.com-200646d09711afeb4bdde2504dd81d74_l3.png\"><br>\n",
    "<img src=\"http://solarisailab.com/wp-content/ql-cache/quicklatex.com-a91b5960b3fee32a6d282dc3e453ee9f_l3.png\"><br>\n",
    "\n",
    "위 식에서 파라미터 Weight와 Bias의 미분값(Derivative)은 예측값과 실제값의 차이-$(\\sigma(z)-y)$-에 비례한다. <br>\n",
    "따라서 오차가 더큰 인풋값에 대해서는 더많이 업데이트하고, 오차가 더 작은 인풋값에 대해서는 더적게 업데이트하는 결과를 얻을 수 있다.\n",
    "\n",
    "또한, 미분값에 $\\sigma'(z)$가 포함되어 있지 않기 때문에 MSE Function을 이용해서 Cost Function을 정의했을때 발생하는 sigmoid function의 특성때문에 발생하는 학습저하(slowdown) 문제도 발생하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back Propagation\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1wOCO2RDqgIrwfEPRRbRJ-MEGmQ36Cmgs\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice - Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:28:30.800520Z",
     "start_time": "2018-10-02T11:28:29.387558Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:28:32.449511Z",
     "start_time": "2018-10-02T11:28:32.445490Z"
    }
   },
   "outputs": [],
   "source": [
    "x = Variable(torch.Tensor([-2.0]),  requires_grad=True)\n",
    "y = Variable(torch.Tensor([5.0]),  requires_grad=True)\n",
    "z = Variable(torch.Tensor([-4.0]),  requires_grad=True)\n",
    "\n",
    "q =  x+y\n",
    "f = q*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:28:33.292929Z",
     "start_time": "2018-10-02T11:28:33.286946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.], requires_grad=True)\n",
      "tensor([5.], requires_grad=True)\n",
      "tensor([-4.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:29:15.467013Z",
     "start_time": "2018-10-02T11:29:15.463049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.], grad_fn=<ThAddBackward>)\n",
      "tensor([-12.], grad_fn=<ThMulBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(q)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:29:51.461059Z",
     "start_time": "2018-10-02T11:29:51.456073Z"
    }
   },
   "outputs": [],
   "source": [
    "f.backward(retain_graph=True) #class로 하면 저 옵션 안넣어도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:30:11.013032Z",
     "start_time": "2018-10-02T11:30:11.009009Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThMulBackward object at 0x0000021DEB150A90>\n"
     ]
    }
   ],
   "source": [
    "print(f.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:30:13.881313Z",
     "start_time": "2018-10-02T11:30:13.877292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThAddBackward object at 0x0000021DEB1502E8>\n"
     ]
    }
   ],
   "source": [
    "print(q.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:30:48.380963Z",
     "start_time": "2018-10-02T11:30:48.374950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.])\n",
      "tensor([-4.])\n",
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Backpropagation\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?id=1Jvlk56B36HPyihMRACOxUFm7FwUTVL3v\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:37:58.561501Z",
     "start_time": "2018-10-02T11:37:58.553524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7311], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "w0 = Variable(torch.Tensor([2.0]),  requires_grad=True)\n",
    "x0 = Variable(torch.Tensor([-1.0]),  requires_grad=True)\n",
    "w1 = Variable(torch.Tensor([-3.0]),  requires_grad=True)\n",
    "x1 = Variable(torch.Tensor([-2.0]),  requires_grad=True)\n",
    "w2 = Variable(torch.Tensor([-3.0]),  requires_grad=True)\n",
    "\n",
    "q1 =  w0*x0\n",
    "q2 = w1*x1\n",
    "f1 = a+b\n",
    "s = f1+w2\n",
    "\n",
    "out = torch.sigmoid(s)\n",
    "print(out)\n",
    "out.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:34:26.169538Z",
     "start_time": "2018-10-02T11:34:26.159576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1966])\n",
      "tensor([0.3932])\n",
      "tensor([-0.3932])\n",
      "tensor([-0.5898])\n",
      "tensor([0.1966])\n"
     ]
    }
   ],
   "source": [
    "print(w0.grad)\n",
    "print(x0.grad)\n",
    "print(w1.grad)\n",
    "print(x1.grad)\n",
    "print(w2.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice - Weight Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:47:07.530219Z",
     "start_time": "2018-10-02T11:47:07.511277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "First Prediction\n",
      "tensor([0.7311], grad_fn=<SigmoidBackward>)\n",
      "=====================\n",
      "Original Weight\n",
      "tensor([2.], requires_grad=True)\n",
      "tensor([-3.], requires_grad=True)\n",
      "tensor([-3.], requires_grad=True)\n",
      "=====================\n",
      "Gradient\n",
      "tensor([0.1058])\n",
      "tensor([0.2115])\n",
      "tensor([-0.1058])\n",
      "=====================\n",
      "Updated Weight\n",
      "tensor([1.9894], requires_grad=True)\n",
      "tensor([-3.0212], requires_grad=True)\n",
      "tensor([-2.9894], requires_grad=True)\n",
      "=====================\n",
      "Second Prediction\n",
      "tensor([0.7433], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\test\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "w0 = Variable(torch.Tensor([2.0]), requires_grad=True)\n",
    "x0 = Variable(torch.Tensor([-1.0]), requires_grad=True)\n",
    "w1 = Variable(torch.Tensor([-3.0]), requires_grad=True)\n",
    "x1 = Variable(torch.Tensor([-2.0]), requires_grad=True)\n",
    "w2 = Variable(torch.Tensor([-3.0]), requires_grad=True)\n",
    "\n",
    "q1 = w0*x0\n",
    "q2 = w1*x1\n",
    "\n",
    "r = q1 + q2\n",
    "s = r + w2\n",
    "\n",
    "out = F.sigmoid(s)\n",
    "print(\"=====================\")\n",
    "print(\"First Prediction\")\n",
    "print(out)\n",
    "\n",
    "target = torch.Tensor([1.0])\n",
    "optimizer = optim.SGD([w0, w1, w2], lr=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "print(\"=====================\")\n",
    "print(\"Original Weight\")\n",
    "print(w0)\n",
    "print(w1)\n",
    "print(w2)\n",
    "\n",
    "\n",
    "loss = criterion(out, target)\n",
    "loss.backward()\n",
    "\n",
    "print(\"=====================\")\n",
    "print(\"Gradient\")\n",
    "\n",
    "print(w0.grad)\n",
    "print(w1.grad)\n",
    "print(w2.grad)\n",
    "\n",
    "optimizer.step() #weight update !\n",
    "\n",
    "print(\"=====================\")\n",
    "print(\"Updated Weight\") # w_new = w_ori - (learning_rate * gradient)\n",
    "\n",
    "print(w0) # w0_new = w0(=2.0) - (0.1 * 0.1058) = 1.9894\n",
    "print(w1) # w1_new = w1(=-3.0) - (0.1 * 0.2115) = -3.0212\n",
    "print(w2) # w2_new = w2(=-3.0) - (0.1 * 0.1058) = -2.9894\n",
    "\n",
    "q1 = w0*x0\n",
    "q2 = w1*x1\n",
    "\n",
    "r = q1 + q2\n",
    "s = r + w2\n",
    "\n",
    "out = torch.sigmoid(s)\n",
    "print(\"=====================\")\n",
    "print(\"Second Prediction\")\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice - Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:51:51.728641Z",
     "start_time": "2018-10-02T11:51:51.723687Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleLinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleLinearRegression, self).__init__() # what is super ?\n",
    "        self.Layer = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.Layer(inputs)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        x = self.Layer(test_input)\n",
    "        return x\n",
    "\n",
    "model = SimpleLinearRegression()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# momentum 추가 속도 및 정확도 비교! - 링크 참고\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:53:18.509700Z",
     "start_time": "2018-10-02T11:53:18.296540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.5791e-14, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8948e-14, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8948e-14, grad_fn=<MseLossBackward>)\n",
      "tensor(1.8948e-14, grad_fn=<MseLossBackward>)\n",
      "tensor(7.5791e-14, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    inputs = torch.Tensor([1.0, 2.0, 3.0]).unsqueeze(1)\n",
    "    targets = torch.Tensor([2.1, 4.1, 6.1]).unsqueeze(1) # y = 2x + 0.1\n",
    "                          \n",
    "    model.zero_grad()\n",
    "    y_pred = model(inputs)\n",
    "    loss = criterion(y_pred, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:53:22.419979Z",
     "start_time": "2018-10-02T11:53:22.414992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.0000]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1000], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "w = list(model.parameters())\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:53:23.377274Z",
     "start_time": "2018-10-02T11:53:23.361316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.1000], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(torch.Tensor([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO - Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T11:54:11.079642Z",
     "start_time": "2018-10-02T11:54:10.980061Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "seed = 777\n",
    "np.random.seed(seed)\n",
    "\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=300, n_features=1, noise=30.0, random_state=seed)\n",
    "\n",
    "X_train = X[:200]\n",
    "X_test = X[200:]\n",
    "y_train = y[:200]\n",
    "y_test = y[200:]\n",
    "\n",
    "\n",
    "# plot regression dataset\n",
    "\n",
    "plt.scatter(X_train,y_train, c=\"r\")\n",
    "plt.scatter(X_test,y_test, c=\"b\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 872.5445482700914\n",
      "y = 39.1679X + -1.5085\n",
      "\n",
      "Mean Squared Error : 820.7126317168555\n",
      "R^2 : 0.6436611039385312\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "print(\"y = %.4fX + %.4f\"%(float(model.coef_[0]),float(model.intercept_)))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_square = r2_score(y_test, y_pred)\n",
    "print()\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "print(\"R^2 :\",r_square)\n",
    "\n",
    "plt.scatter(X_test, y_test, c=\"b\")\n",
    "plt.plot(X_test, y_pred, c=\"r\", linewidth=3)\n",
    "plt.legend([\"reg\",\"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 39.1679X + -1.5085\n"
     ]
    }
   ],
   "source": [
    "w = list(model.parameters())\n",
    "print(\"y = %.4fX + %.4f\"%(w[0].item(), w[1].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 820.7126222618163\n",
      "R^2 : 0.6436611080437418\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(torch.Tensor(X_test)).detach().numpy()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_square = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "print(\"R^2 :\",r_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice - Multiple Linear Regression\n",
    "\n",
    "### 보스턴 주택 가격 데이터\n",
    "\n",
    "1978 미국 보스턴의 주택 가격 데이터이다.  `load_boston()` 명령으로 로드하며 다음과 같이 구성되어 있다.\n",
    "\n",
    "* 타겟 데이터\n",
    " * `MEDV`: 506 타운의 주택 가격 중앙값 (단위 1,000 달러)<br><br>\n",
    " \n",
    "* 특징 데이터 \n",
    " * `CRIM`: 범죄율\n",
    " * `ZN`: 25,000 평방피트를 초과 거주지역 비율\n",
    " * `INDUS`: 비소매상업지역 면적 비율\n",
    " * `CHAS`: 찰스강의 경계에 위치한 경우는 1, 아니면 0\n",
    " * `NOX`: 일산화질소 농도 \n",
    " * `RM`: 주택당 방 수\n",
    " * `AGE`: 1940년 이전에 건축된 주택의 비율\n",
    " * `DIS`: 직업센터의 거리\n",
    " * `RAD`: 방사형 고속도로까지의 거리\n",
    " * `TAX`:\t재산세율\n",
    " * `PTRATIO`: 학생/교사 비율\n",
    " * `B`: 인구 중 흑인 비율\n",
    " * `LSTAT`: 인구 중 하위 계층 비율\n",
    " \n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfX = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "dfy = pd.DataFrame(boston.target, columns=[\"MEDV\"])\n",
    "df = pd.concat([dfX, dfy], axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.593761</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.596783</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.647423</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.593761   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.596783   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.647423   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.3, random_state=777)\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 21.025226779107708\n",
      "\n",
      "Mean Squared Error : 25.357256011214208\n",
      "R^2 : 0.6999392625722696\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_square = r2_score(y_test, y_pred)\n",
    "print()\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "print(\"R^2 :\",r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class makeData(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.X_data[index], self.y_data[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y_data)\n",
    "\n",
    "train_data = makeData(X_train, y_train)\n",
    "test_data = makeData(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleLinearRegression(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(MultipleLinearRegression, self).__init__()\n",
    "        self.Layer = nn.Linear(feature_size, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.Layer(inputs)\n",
    "        return x.squeeze(1)\n",
    "    \n",
    "    def predict(self, test_input):\n",
    "        x = self.Layer(test_input)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6274.5742)\n",
      "tensor(44.0246)\n",
      "tensor(33.4632)\n",
      "tensor(17.9946)\n",
      "tensor(26.1190)\n",
      "tensor(36.1893)\n",
      "tensor(14.8336)\n",
      "tensor(23.1527)\n",
      "tensor(40.8293)\n",
      "tensor(36.7753)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2500\n",
    "BATCH_SIZE = 100\n",
    "FEATURE_SIZE = len(boston.data[0])\n",
    "\n",
    "model = MultipleLinearRegression(FEATURE_SIZE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# momentum 추가 속도 및 정확도 비교! - 링크 참고\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_batch = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "for epoch in range(EPOCHS):\n",
    "    for X_batch, y_batch in train_batch:\n",
    "        inputs = torch.Tensor(X_batch.float())\n",
    "        targets = torch.Tensor(y_batch.float())\n",
    "        model.zero_grad()\n",
    "        y_pred = model(inputs)\n",
    "        loss = criterion(y_pred, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 250 == 0:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error : 23.282666521125282\n",
      "R^2 : 0.7244885612811127\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(torch.Tensor(X_test)).detach().numpy()\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_square = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error :\",mse)\n",
    "print(\"R^2 :\",r_square)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
